{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "- A cluster is a group of data points that are similar to data points in their cluster AND dissimilar to data points in other clusters.\n",
    "- It is used in customer segmentation(profiling), identifiying buying patterns, **recommendation systems**, categorizing news\n",
    "- Also used in credit card fraud detection\n",
    "- It can be used as a part of EDA too\n",
    "\n",
    "## Clustering Algorithms\n",
    "- **Partition-based Clustering**\n",
    "    - Relatively efficient\n",
    "    - K-Means, K-Median, Fuzzy c-means\n",
    "\n",
    "- **Hierarchical Clustering**\n",
    "    - Produces trees of clusters\n",
    "    - Good with smaller data sets\n",
    "    \n",
    "- **Density-based Clustering**\n",
    "    - Produces arbitrary shaped clusters\n",
    "    - Good when dealing with special clusters OR when there's noise in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\n",
    "- A type of partitioning clustering\n",
    "- Divides the data into **non-overlapping** subsets\n",
    "- High similarity within clusters, high dissimilarity between clusters\n",
    "- Relatively efficient with medium and large sized datasets\n",
    "- Produces sphere-like clusters\n",
    "\n",
    "### Dissimilarity (distance)\n",
    "- Similarity distance (Minkowski):\n",
    "    - Dis(x1, x2) = (sum for each i: (x1i - x2i) ^ 2) ^ 0.5\n",
    " - Normalization does more good then harm on most occasions\n",
    " \n",
    "### How does it work?\n",
    "1. Randomly pick a center point (centroid) for each cluster\n",
    "    - These center points should be of same feature size of our data set\n",
    "    - You can pick k number of observations for centroids\n",
    "    - OR you can pick just random points (this one looks better isn't it)\n",
    "2. Calculate the distance of each data point from the centroids: **Create a Distance matrix**\n",
    "    - Error metric: Sum of the squared distances between each point and its centroid\n",
    "3. Assign each point to the closest centroid\n",
    "4. **To minimize error, update the centroids to be the mean for data points in its cluster.**\n",
    "5. Iteratively do steps 1-4 and minimize the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Accuracy\n",
    "- **External Approach** (We won't be able to do it much in the real world, since it's unsupervised learning)\n",
    "    - Compare the clusters with the ground truth, if available\n",
    "- **Internal Approach**\n",
    "    - Average the distance between data points within a cluster\n",
    "- **Choosing K**\n",
    "    - As K increases, the error would decrease\n",
    "    - However, when you plot the accuracy with different K's, the elbow point is the best K.\n",
    "    - Elbow point: The point where the major slope change happens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
