{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression: Process of predicting a continuous value\n",
    "    ####Dependent variables: Data field/s to be predicted\n",
    "    ####Independent variables: Not dependent lol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Regression: Single independent variable (CO2 emission using EngineSize)\n",
    "    Simple Linear Regression\n",
    "    Simple Non-Linear Regression\n",
    "\n",
    "#### Multiple Regression: Multiple independent variables (CO2 emission using EngineSize and Cylinders)\n",
    "    Multiple Linear Regression\n",
    "    Multiple Non-Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Linear Regression\n",
    "\n",
    "- Linear regression is the approximation of a linear model used to describe the relationship between two or more variables.\n",
    "- The key point in the linear regression is that our dependent value should be continuous and cannot be a discrete value.\n",
    "- Y = A + Bx\n",
    "- Residual error: Distance between prediction and real value: y - Y\n",
    "    - The Mean of all Residual errors shows how poorly the line fits with the whole data set.\n",
    "    - Mean Squared Error: MSE = 1/n * (for i in range(n): err += (y - Y)^2)\n",
    "    - To find the best fit, MSE must be minimized\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best Fit Line\n",
    "\n",
    "#### Mathematical Approach:\n",
    "- Knowing that it is a simple linear regression with only two parameters,\n",
    "- Knowing that theta 0 and theta 1 are the intercept and the slope of the line,\n",
    "- We can estimate them directly from our data.\n",
    "    \n",
    "    - Theta 1 = (x[i] - x)*(y[i] - y) / (x[i] - x)^2 for i in range len(column)\n",
    "    - Theta 0 = y - Theta1 * x\n",
    "    - Theta 0 is also called as the \"bias coefficient\"\n",
    "    - Y(Dependent var) = Theta 0 + Theta1 * X(Independent var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation Approaches\n",
    "\n",
    "#### Train and Test on the same Data set\n",
    "- Train the model with entire data set, then test it on a portion of the data set\n",
    "- Then we compare the predictions with the actual values of the test set\n",
    "- Error is calculated as the average of y(actual) - Y(predicted) for each value\n",
    "- This approach has high \"Training accuracy\" and low \"Out-of-sample accuracy\"\n",
    "- High training accuracy is not necessarily a good thing, it can cause overfitting.\n",
    "- Out-of-sample accuracy is more important\n",
    "\n",
    "#### Train-Test Split\n",
    "- We select a portion of our data set for training, and another portion for testing\n",
    "- Higher Out-of-sample accuracy, more realistic for real world problems\n",
    "- Highly dependent on the data sets used for training and testing\n",
    "    \n",
    "#### K-Fold Cross Validation\n",
    "- If we have K=4, then the data set is splitted to 4 folds.\n",
    "- The model is trained from the other 3 folds, while each fold becomes the test set once.\n",
    "- The accuracy of each fold is averaged and then we get the accuracy of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "#### Error: Measure of how far the data is from the fitted regression line.\n",
    "\n",
    "- MAE (Mean Absolute Error): Mean of the distance of all data points\n",
    "\n",
    "\n",
    "- MSE (Mean Squared Error): Same but instead of taking abs, we square the distance. Shows the criticality of larger errors in a better way.\n",
    "\n",
    "\n",
    "- RMSE (Root Mean Squared Error): Sqrt of MSE, the most popular because it's interpretable as the response vector of y units.\n",
    "\n",
    "\n",
    "- RAE (Relative Absolute Error): Distances of all data points divided by the distances of all data points from that of the predictor.\n",
    "\n",
    "\n",
    "- RSE (Relative Squared Error): Same but instead of taking abs, we square the distances in RAE. R squared is an accuracy metric that is calculated with R^2 = (1 - RSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
